
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>classifierLib &#8212; Senior Thesis  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for classifierLib</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">classifierLib.py</span>
<span class="sd">Author: Adam Hare &lt;adamth@alumni.princeton.edu&gt;</span>
<span class="sd">Last Updated: 6 September 2018</span>

<span class="sd">Description:</span>
<span class="sd">This file contains a number of functions used to train and evaluate data using the machine learning classifiers.</span>
<span class="sd">Some of these functions may be very time-intensive depending on the size of the data set. They are also configured to</span>
<span class="sd">run on either Princeton&#39;s Nobel or Adroit computing cluster and so some configuration changes may be required depending</span>
<span class="sd">on where the programs are being run.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">k</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="k">import</span> <span class="n">hstack</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<div class="viewcode-block" id="split_data"><a class="viewcode-back" href="../index.html#classifierLib.split_data">[docs]</a><span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">frac</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a `pandas` `DataFrame`, this function splits it into two parts based on the provided fraction and returns</span>
<span class="sd">    both.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: The data to be split, in the form of a `pandas` `DataFrame`.</span>

<span class="sd">        frac: The fraction of data to be put in the first result. The rest will be returned in the second result. This</span>
<span class="sd">        number should range from 0 to 1 inclusive, where 0 puts all data in the second result and 1 puts all data in the</span>
<span class="sd">        first result.</span>

<span class="sd">        shuffle: A boolean value indicating whether or not to shuffle the data. If `False`, the data will be returned</span>
<span class="sd">        in the order it was received.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Two `pandas` `DataFrame` objects, the first with `frac` * 100 percent of the data and the other with (1-`frac`)</span>
<span class="sd">        * 100 percent of the data.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Thrown if the `frac` parameter is not between 0 and 1.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="c1"># Ensure frac is a valid decimal.</span>
    <span class="k">if</span> <span class="n">frac</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">frac</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Frac must be between zero and one.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">n_first</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">frac</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">shuffler</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">shuffler</span><span class="p">[:</span><span class="n">n_first</span><span class="p">]],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">shuffler</span><span class="p">[</span><span class="n">n_first</span><span class="p">:]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="n">n_first</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">n_first</span><span class="p">:]</span></div>


<div class="viewcode-block" id="merge_data"><a class="viewcode-back" href="../index.html#classifierLib.merge_data">[docs]</a><span class="k">def</span> <span class="nf">merge_data</span><span class="p">(</span><span class="n">file_names</span><span class="p">,</span> <span class="n">frac</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function takes a list of file paths to csv files, reads each into a `pandas` `DataFrame` object, and returns a</span>
<span class="sd">    `DataFrame` consisting of the data from all of these files combined. This is useful for combining data from</span>
<span class="sd">    different files.</span>

<span class="sd">    Args:</span>
<span class="sd">        file_names: The paths to the files to be merged as a list.</span>

<span class="sd">        frac: The fraction of each data in each file to be retained. This can vary from 0 to 1 inclusive, with 0</span>
<span class="sd">        resulting in no data being read from any of the files and 1 reading all available data.</span>

<span class="sd">        shuffle: A boolean value indicating whether or not the data will be shuffled. If `False`, the data will be</span>
<span class="sd">        returned in the order it appeared in each file, in the order the files were given in the list.</span>

<span class="sd">    Returns:</span>
<span class="sd">        One `pandas` `DataFrame` with all of the read data.</span>

<span class="sd">    Raises:</span>
<span class="sd">        IndexError: Thrown if no file_names is an empty list.</span>

<span class="sd">        ValueError: Thrown by `split_data` if `frac` is invalid.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">file</span> <span class="o">=</span> <span class="n">file_names</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Split the data if required. Skip this possibly expensive operation if all data is used.</span>
        <span class="k">if</span> <span class="n">frac</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">frac</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">:</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Split the data if required. Skip this possibly expensive operation if all data is used.</span>
            <span class="k">if</span> <span class="n">frac</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">new_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">frac</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">)</span>

            <span class="c1"># Concatenate this with the all of the data already read.</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data</span><span class="p">,</span> <span class="n">new_data</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span>

    <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Must include at least one data file.&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_bag_of_words"><a class="viewcode-back" href="../index.html#classifierLib.get_bag_of_words">[docs]</a><span class="k">def</span> <span class="nf">get_bag_of_words</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">is_tf</span><span class="p">,</span> <span class="n">use_stop_words</span><span class="p">,</span> <span class="n">is_binary</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function creates and returns a weighted bag of words from the data based on the provided parameters. `data` is</span>
<span class="sd">    expected to be a single column from a `pandas` `DataFrame`, typically &quot;Body&quot; in this use case.</span>

<span class="sd">    Args:</span>

<span class="sd">        data: A `pandas` `DataFrame` from which the bag of words will be built.</span>

<span class="sd">        vectorizer: The model used to make the bag of words. If `None`, a new bag of words is created by the other</span>
<span class="sd">        parameters. If provided, following parameters are ignored and the vectorizer is used instead.</span>

<span class="sd">        is_tf: A boolean value indicating whether or not to use the TF-IDF weighting. If `True`, TF-IDF is used and if</span>
<span class="sd">        `False` the appearances of words are simply counted.</span>

<span class="sd">        use_stop_words: A boolean value indicating whether or not to remove common stop words from the data. When</span>
<span class="sd">        `True`, common English stop words are removed and when `False` all words are considered.</span>

<span class="sd">        is_binary: A boolean value indicating whether or not to use a binary weighting for word appearances. If `True`,</span>
<span class="sd">        any words that appear at least once will get a weight of 1 and all words that don&#39;t appear a weight 0. This</span>
<span class="sd">        carries over to TF-IDF, but the TF-IDF still returns a range of values, only considering the word count part of</span>
<span class="sd">        it as binary.</span>


<span class="sd">    Returns:</span>
<span class="sd">        The bag of words data and the vectorizer used to create it.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="c1"># Check if we got a vectorizer, in which case use it and return.</span>
    <span class="k">if</span> <span class="n">vectorizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">vectorizer</span>

    <span class="c1"># Using TF-IDF weighting</span>
    <span class="k">if</span> <span class="n">is_tf</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_stop_words</span><span class="p">:</span>
            <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="n">is_binary</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="n">is_binary</span><span class="p">)</span>

    <span class="c1"># Using standard word count weighting</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_stop_words</span><span class="p">:</span>
            <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="n">is_binary</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="n">is_binary</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">vectorizer</span></div>


<div class="viewcode-block" id="scale_features"><a class="viewcode-back" href="../index.html#classifierLib.scale_features">[docs]</a><span class="k">def</span> <span class="nf">scale_features</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feature_list</span><span class="p">,</span> <span class="n">additional_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function scales and returns the appropriate feature columns.</span>

<span class="sd">    Args:</span>

<span class="sd">        data: The `pandas` `DataFrame` containing the relevant data.</span>

<span class="sd">        feature_list: A string list of features to be used in analysis, in this case the names of the columns in `data`</span>
<span class="sd">        to be used.</span>

<span class="sd">        additional_features: Any additional features not provided in `data` that need to be added. In this case,</span>
<span class="sd">        &#39;additional_features` is often the bag of words returned by get_bag_of_words.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `numpy` `ndarray` consisting of the columns of `feature_list` scaled and concatenated with those in</span>
<span class="sd">        `additional_data`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="c1"># Ensure we have some features from the data to scale.</span>
    <span class="k">if</span> <span class="n">feature_list</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">feature_list</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hstack</span><span class="p">([</span><span class="n">additional_features</span><span class="p">,</span> <span class="n">features</span><span class="p">])</span>
    <span class="c1"># Otherwise, just return the additional features. Note that this list may be empty, in which case the function</span>
    <span class="c1"># returns an empty list.</span>
    <span class="k">return</span> <span class="n">additional_features</span></div>


<div class="viewcode-block" id="get_precision"><a class="viewcode-back" href="../index.html#classifierLib.get_precision">[docs]</a><span class="k">def</span> <span class="nf">get_precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate precision. This is drawn from old `keras` source code.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_true: The ground truth labels for the data set.</span>

<span class="sd">        y_predicted: The predicted labels for the data set, as returned by the classifier.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A float signifying the classifier&#39;s precision on the given data set.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="n">true_positives</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">predicted_positives</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_predicted</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">precision</span></div>


<div class="viewcode-block" id="get_recall"><a class="viewcode-back" href="../index.html#classifierLib.get_recall">[docs]</a><span class="k">def</span> <span class="nf">get_recall</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate recall. This is drawn from old `keras` source code.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_true: The ground truth labels for the data set.</span>

<span class="sd">        y_predicted: The predicted labels for the data set, as returned by the classifier.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A float signifying the classifier&#39;s recall on the given data set.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="n">true_positives</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">possible_positives</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">possible_positives</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">recall</span></div>


<div class="viewcode-block" id="get_f_score"><a class="viewcode-back" href="../index.html#classifierLib.get_f_score">[docs]</a><span class="k">def</span> <span class="nf">get_f_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate F Score.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_true: The ground truth labels for the data set.</span>

<span class="sd">        y_predicted: The predicted labels for the data set, as returned by the classifier.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A float signifying the classifier&#39;s F Score on the given data set.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="n">pre</span> <span class="o">=</span> <span class="n">get_precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">)</span>
    <span class="n">rec</span> <span class="o">=</span> <span class="n">get_recall</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">pre</span><span class="o">*</span><span class="n">rec</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">pre</span> <span class="o">+</span> <span class="n">rec</span><span class="p">)</span></div>


<div class="viewcode-block" id="config_cluster"><a class="viewcode-back" href="../index.html#classifierLib.config_cluster">[docs]</a><span class="k">def</span> <span class="nf">config_cluster</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Change some settings to allow this code to work with cluster computers.</span>

<span class="sd">    Args:</span>
<span class="sd">        None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="c1"># Fixes out of memory errors on Nobel.</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
    <span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">k</span><span class="o">.</span><span class="n">set_session</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">))</span></div>


<div class="viewcode-block" id="get_measures"><a class="viewcode-back" href="../index.html#classifierLib.get_measures">[docs]</a><span class="k">def</span> <span class="nf">get_measures</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">print_latex</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates some important measures on the results of an SVM classification.</span>

<span class="sd">    Args:</span>
<span class="sd">        true_labels: A vector of ground truth labels.</span>

<span class="sd">        predicted_labels: A vector of labels predicted by the classifier.</span>

<span class="sd">        iteration: Which iteration these results correspond to, for use with shuffled data. Default is `False`, which</span>
<span class="sd">        does not print any iteration information. This is available in case the classifier is called in a loop.</span>

<span class="sd">        verbose: A boolean indicating whether or not to print all results on separate lines. Default is `False`, which</span>
<span class="sd">        does not print any values in this manner.</span>

<span class="sd">        print_latex: A boolean indicating whether or not to print the data formatted for a `LaTeX` table. Default is</span>
<span class="sd">        `False`, which doesn&#39;t print anything.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Four floats, corresponding to the accuracy, precision, recall, and F Score of the classifier for the given data.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Additional errors may be thrown by dependencies.</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="c1"># Initialize variables.</span>
    <span class="n">true_positive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">false_positive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">true_negative</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">false_negative</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_labels</span><span class="p">)</span>

    <span class="c1"># create a count of each type of classification</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">true_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">predicted_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">true_positive</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">false_positive</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">predicted_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">false_negative</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">true_negative</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Check that every article was evaluated properly.</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">n</span> <span class="o">==</span> <span class="n">true_positive</span> <span class="o">+</span> <span class="n">false_positive</span> <span class="o">+</span> <span class="n">true_negative</span> <span class="o">+</span> <span class="n">false_negative</span><span class="p">)</span>

    <span class="c1"># Print the iteration number and result of each classification type</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration = </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">iteration</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TP = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">true_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FP = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">false_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FN = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">false_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TN = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">true_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">))</span>

    <span class="c1"># Calculate desired measures.</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_positive</span> <span class="o">+</span> <span class="n">true_negative</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>

    <span class="c1"># For sufficiently large and complex data sets, all of these should take some value. For testing, they don&#39;t always.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">true_positive</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positive</span> <span class="o">+</span> <span class="n">false_positive</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision caused divide by zero error.&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># For sufficiently large and complex data sets, all of these should take some value. For testing, they don&#39;t always.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">true_positive</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positive</span> <span class="o">+</span> <span class="n">false_negative</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall caused divide by zero error.&quot;</span><span class="p">)</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">f_score</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>

    <span class="c1"># Print the measures if verbose.</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">accuracy</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">precision</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">recall</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F = </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">f_score</span><span class="p">)</span>

    <span class="c1"># Print in `LaTeX` format.</span>
    <span class="k">if</span> <span class="n">print_latex</span><span class="p">:</span>
        <span class="c1"># Print with iteration.</span>
        <span class="k">if</span> <span class="n">iteration</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="se">\\\\</span><span class="s2">&quot;</span> <span class="o">%</span>
                  <span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">true_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">false_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">false_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">true_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                   <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f_score</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="s2"> &amp; </span><span class="si">%.4f</span><span class="se">\\\\</span><span class="s2">&quot;</span> <span class="o">%</span>
                  <span class="p">(</span><span class="n">true_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">false_positive</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">false_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">true_negative</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span>
                   <span class="n">recall</span><span class="p">,</span> <span class="n">f_score</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f_score</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Senior Thesis</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Adam Hare.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.8</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
    </div>

    

    
  </body>
</html>